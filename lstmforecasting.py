# -*- coding: utf-8 -*-
"""LSTMForecasting.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1a9_JiVe4l2XtL3c28mn4sAQMx2HSXfk0
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import math
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
from keras.models import Sequential
from keras.layers import Dense, Activation
from keras.layers import LSTM
import pandas as pd
import preprocessing

def Replace_Outliers(l1):
    l1 = pd.DataFrame({'col': l1})
    Q1 = np.percentile(l1, 25, interpolation='midpoint')
    Q3 = np.percentile(l1, 75, interpolation='midpoint')

    IQR = Q3 - Q1
    df2 = pd.DataFrame(l1)
    outliers = l1[((l1 < (Q1 - 1.5 * IQR)) | (l1 > (Q3 + 1.5 * IQR)))]
    outliers.dropna(inplace=True, axis=0)
    # df=outliers

    outliers = list(outliers.values)
    rep = np.median(l1)
    df2[df2.columns[0]] = df2[df2.columns[0]].replace(outliers, rep)

    #   return list(outliers.flatten())
    return list(df2.values.flatten())

data = pd.read_excel("/content/cona_sample.xlsx")
data.inv_invoice_date = pd.to_datetime(data.inv_invoice_date)
data

data=data.groupby(['inv_invoice_date']).sum(['inv_itemwise_value_reporting_amount']).reset_index()

data.drop(columns='inv_invoice_date',inplace=True)

# Scale the data using MinMaxScaler
scaler = MinMaxScaler(feature_range=(0, 1))
data_scaled = scaler.fit_transform(data)

# Split the data into training and test sets
train_size = int(len(data_scaled) * 0.8)
test_size = len(data_scaled) - train_size
train, test = data_scaled[0:train_size, :], data_scaled[train_size:len(data_scaled), :]

# Convert the data into a 3D array (samples, timesteps, features)
def create_dataset(data, look_back=1):
    data_X, data_y = [], []
    for i in range(len(data) - look_back):
        a = data[i:(i + look_back), :]
        data_X.append(a)
        data_y.append(data[i + look_back, :])
    return np.array(data_X), np.array(data_y)

look_back = 1
train_X, train_y = create_dataset(train, look_back)
test_X, test_y = create_dataset(test, look_back)

# Reshape the data into the shape accepted by the LSTM
train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))
test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))

# Create the LSTM model
model = Sequential()
model.add(LSTM(50, input_shape=(1, look_back)))
model.add(Dense(1))
model.compile(loss='mean_squared_error', optimizer='adam')

# Fit the LSTM to the training data
model.fit(train_X, train_y, epochs=100, batch_size=1, verbose=2)

# Make predictions on the test data
predictions = model.predict(test_X)

# Reverse the scaling on the predictions and test_y
predictions = scaler.inverse_transform(predictions)
test_y = scaler.inverse_transform(test_y)

# Print the mean squared error of the predictions
print('Mean Squared Error:', np.mean((predictions - test_y)**2))

# Predict tomorrow's sales
tomorrow_sales = model.predict(np.array([test_X[-1]]))
tomorrow_sales = scaler.inverse_transform(tomorrow_sales)

print(tomorrow_sales)

data

